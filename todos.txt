connect lamma api and test
create a ui 

consider calling the OpenAI API from server-side code in Next.js, such as in API routes
Create a server side route where the environment variable functions correctly

// pages/api/openai.js

import OpenAI from 'openai';

export default async function handler(req, res) {
    if (req.method === 'POST') {
        try {
            const { prompt } = req.body;
            const openai = new OpenAI({
                apiKey: process.env.OPENAI_API_KEY
            });

            const response = await openai.chat.completions.create({
                model: "gpt-4o",
                messages: [{ role: 'user', content: prompt }]
            });

            res.status(200).json({ result: response.choices[0].message.content });
        } catch (error) {
            console.error('OpenAI API error:', error);
            res.status(500).json({ error: 'Failed to fetch response from OpenAI' });
        }
    } else {
        // Handle any other HTTP method
        res.setHeader('Allow', ['POST']);
        res.status(405).end(`Method ${req.method} Not Allowed`);
    }
}
